{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b41fa2af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: textblob in c:\\users\\hp\\anaconda3\\envs\\skyhack_kunal\\lib\\site-packages (0.17.1)\n",
      "Requirement already satisfied: nltk>=3.1 in c:\\users\\hp\\anaconda3\\envs\\skyhack_kunal\\lib\\site-packages (from textblob) (3.8.1)\n",
      "Requirement already satisfied: click in c:\\users\\hp\\anaconda3\\envs\\skyhack_kunal\\lib\\site-packages (from nltk>=3.1->textblob) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\hp\\anaconda3\\envs\\skyhack_kunal\\lib\\site-packages (from nltk>=3.1->textblob) (1.3.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\hp\\anaconda3\\envs\\skyhack_kunal\\lib\\site-packages (from nltk>=3.1->textblob) (2023.8.8)\n",
      "Requirement already satisfied: tqdm in c:\\users\\hp\\anaconda3\\envs\\skyhack_kunal\\lib\\site-packages (from nltk>=3.1->textblob) (4.66.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\hp\\anaconda3\\envs\\skyhack_kunal\\lib\\site-packages (from click->nltk>=3.1->textblob) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b2e4502",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in c:\\users\\hp\\anaconda3\\envs\\skyhack_kunal\\lib\\site-packages (4.3.2)\n",
      "Requirement already satisfied: numpy>=1.18.5 in c:\\users\\hp\\appdata\\roaming\\python\\python39\\site-packages (from gensim) (1.24.1)\n",
      "Requirement already satisfied: scipy>=1.7.0 in c:\\users\\hp\\anaconda3\\envs\\skyhack_kunal\\lib\\site-packages (from gensim) (1.11.2)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\hp\\anaconda3\\envs\\skyhack_kunal\\lib\\site-packages (from gensim) (6.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1924a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from textblob import TextBlob\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models import LdaModel\n",
    "from gensim import corpora\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "660470f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path=\"C:\\\\Users\\\\HP\\\\Desktop\\\\United Airlines\\\\Datasets\\\\New_Datasets\\\\Senti\\\\input.csv\"\n",
    "output_path=\"C:\\\\Users\\\\HP\\\\Desktop\\\\United Airlines\\\\Datasets\\\\New_Datasets\\\\Senti\\\\output.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a69e1a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "data=pd.read_csv(input_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5155d1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function for classfication task\n",
    "def classify_feedback(text):\n",
    "    \n",
    "    def your_sentiment_analysis_function(text):\n",
    "        analysis = TextBlob(text)\n",
    "        sentiment_score=analysis.sentiment.polarity\n",
    "        return sentiment_score\n",
    "    sentiment_score = your_sentiment_analysis_function(text)\n",
    "    \n",
    "    if sentiment_score > 0:\n",
    "        return 1, 0, 0\n",
    "    elif sentiment_score < 0:\n",
    "        return 0, 1, 0\n",
    "    else:\n",
    "        return 0, 0, 1\n",
    "\n",
    "data[[\"positive\", \"negative\", \"neutral\"]] = data[\"verbatim_text\"].apply(classify_feedback).apply(pd.Series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "58c21c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save it\n",
    "data.to_csv(output_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4beb668e",
   "metadata": {},
   "source": [
    "## Words Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8033d62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "597431ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8a885041",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV data into a pandas DataFrame\n",
    "df = pd.read_csv(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d8bcd2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the SentimentIntensityAnalyzer\n",
    "sia = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f87d82d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_words(row):\n",
    "    text = row['verbatim_text']\n",
    "    sentiment = row['sentiment']  # 'positive', 'neutral', or 'negative'\n",
    "    \n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # Get sentiment scores for each word\n",
    "    word_sentiments = [sia.polarity_scores(word) for word in tokens]\n",
    "    \n",
    "    # Extract words based on sentiment score\n",
    "    if sentiment == 'positive':\n",
    "        extracted_words = [tokens[i] for i, sent_score in enumerate(word_sentiments) if sent_score['compound'] > 0]\n",
    "    elif sentiment == 'neutral':\n",
    "        extracted_words = [tokens[i] for i, sent_score in enumerate(word_sentiments) if sent_score['compound'] == 0]\n",
    "    else:  # Negative sentiment\n",
    "        extracted_words = [tokens[i] for i, sent_score in enumerate(word_sentiments) if sent_score['compound'] < 0]\n",
    "    \n",
    "    return ', '.join(extracted_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c93e7f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a 'sentiment' column based on existing 'positive', 'neutral', and 'negative' columns\n",
    "df['sentiment'] = df.apply(lambda row: 'positive' if row['positive'] == 1 else ('neutral' if row['neutral'] == 1 else 'negative'), axis=1)\n",
    "\n",
    "# Apply the extract_words function to each row and create a new 'words' column\n",
    "df['words'] = df.apply(extract_words, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "409a7dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the updated DataFrame to a new CSV file\n",
    "df.to_csv(\"C:\\\\Users\\\\HP\\\\Desktop\\\\United Airlines\\\\Datasets\\\\New_Datasets\\\\Senti\\\\wordsnew.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d38740a",
   "metadata": {},
   "source": [
    "# WordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cc7bfb21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wordcloud in c:\\users\\hp\\anaconda3\\envs\\skyhack_kunal\\lib\\site-packages (1.9.2)\n",
      "Requirement already satisfied: numpy>=1.6.1 in c:\\users\\hp\\appdata\\roaming\\python\\python39\\site-packages (from wordcloud) (1.24.1)\n",
      "Requirement already satisfied: pillow in c:\\users\\hp\\anaconda3\\envs\\skyhack_kunal\\lib\\site-packages (from wordcloud) (10.0.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\hp\\anaconda3\\envs\\skyhack_kunal\\lib\\site-packages (from wordcloud) (3.7.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\hp\\anaconda3\\envs\\skyhack_kunal\\lib\\site-packages (from matplotlib->wordcloud) (1.1.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\hp\\anaconda3\\envs\\skyhack_kunal\\lib\\site-packages (from matplotlib->wordcloud) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\hp\\anaconda3\\envs\\skyhack_kunal\\lib\\site-packages (from matplotlib->wordcloud) (4.42.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\hp\\anaconda3\\envs\\skyhack_kunal\\lib\\site-packages (from matplotlib->wordcloud) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\hp\\appdata\\roaming\\python\\python39\\site-packages (from matplotlib->wordcloud) (22.0)\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in c:\\users\\hp\\anaconda3\\envs\\skyhack_kunal\\lib\\site-packages (from matplotlib->wordcloud) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\hp\\anaconda3\\envs\\skyhack_kunal\\lib\\site-packages (from matplotlib->wordcloud) (2.8.2)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in c:\\users\\hp\\anaconda3\\envs\\skyhack_kunal\\lib\\site-packages (from matplotlib->wordcloud) (6.0.1)\n",
      "Requirement already satisfied: zipp>=3.1.0 in c:\\users\\hp\\appdata\\roaming\\python\\python39\\site-packages (from importlib-resources>=3.2.0->matplotlib->wordcloud) (3.11.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\hp\\appdata\\roaming\\python\\python39\\site-packages (from python-dateutil>=2.7->matplotlib->wordcloud) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d4ea2c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "91c6710b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the updated DataFrame to a new CSV file\n",
    "df=pd.read_csv(\"C:\\\\Users\\\\HP\\\\Desktop\\\\United Airlines\\\\Datasets\\\\New_Datasets\\\\Senti\\\\wordsnew.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a541fdca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows with missing 'words' values\n",
    "df = df.dropna(subset=['words'])\n",
    "\n",
    "# List of sentiments\n",
    "sentiments = ['positive', 'neutral', 'negative']\n",
    "\n",
    "# Loop through each sentiment category\n",
    "for sentiment in sentiments:\n",
    "    sentiment_df = df[df['sentiment'] == sentiment]\n",
    "    all_words = ' '.join(sentiment_df['words'])\n",
    "    \n",
    "    wordcloud = WordCloud(width=800, height=800, background_color='white').generate(all_words)\n",
    "    \n",
    "    plt.figure(figsize=(8, 8), facecolor=None)\n",
    "    plt.imshow(wordcloud)\n",
    "    plt.axis(\"off\")\n",
    "    plt.tight_layout(pad=0)\n",
    "    plt.title(f'Word Cloud for {sentiment.capitalize()} Sentiment')\n",
    "    \n",
    "    image_path = f'C:\\\\Users\\\\HP\\\\Desktop\\\\United Airlines\\\\Datasets\\\\New_Datasets\\\\Senti\\\\wordcloud_{sentiment}.png'\n",
    "    plt.savefig(image_path)\n",
    "    plt.close()  # Close the plot to save memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3500df32",
   "metadata": {},
   "source": [
    "# END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa0ad38f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
